<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Configure Overwatch on Overwatch</title>
    <link>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/</link>
    <description>Recent content in Configure Overwatch on Overwatch</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Tue, 13 Dec 2022 14:48:09 -0500</lastBuildDate>
    <atom:link href="https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Configuration</title>
      <link>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/configuration/</link>
      <pubDate>Mon, 12 Dec 2022 11:35:40 -0500</pubDate>
      <guid>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/configuration/</guid>
      <description>&lt;h2 id=&#34;overwatch-deployment-configuration&#34;&gt;Overwatch Deployment Configuration&lt;/h2&gt;&#xA;&lt;h3 id=&#34;how-it-works&#34;&gt;How it works&lt;/h3&gt;&#xA;&lt;p&gt;Overwatch deployment is driven by a configuration file which will ultimately be loaded into the deployment as&#xA;a csv format or delta table. This configuration will contain all the necessary details to perform the deployment. Since CSVs are a bit&#xA;cantankerous we&amp;rsquo;ve offered two different methods for building the configuration file. If you&amp;rsquo;re good at VSCode or&#xA;similar text editor and want to edit the CSV directly feel free to do so. We &lt;strong&gt;strongly&lt;/strong&gt; recommend that you create a delta&#xA;table with the csv file you just created and use that as your configuration input.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Custom Costs</title>
      <link>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/customcosts/</link>
      <pubDate>Tue, 13 Dec 2022 14:35:00 -0500</pubDate>
      <guid>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/customcosts/</guid>
      <description>&lt;h2 id=&#34;fine-tuning-your-costs&#34;&gt;Fine-Tuning Your Costs&lt;/h2&gt;&#xA;&lt;p&gt;Every customer has their own contracts and this means that the costs associated with cloud compute and DBUs may differ&#xA;between customers. To ensure the costs in Overwatch are as accurate as possible it&amp;rsquo;s important that these costs are&#xA;configured as accurately as possible.&lt;/p&gt;&#xA;&lt;h3 id=&#34;configuring-custom-costs&#34;&gt;Configuring Custom Costs&lt;/h3&gt;&#xA;&lt;p&gt;There are three essential components to the cost function:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The node type (instanceDetails.Api_Name) and its associated contract price (instanceDetails.Compute_Contract_Price)&#xA;by Workspace&lt;/li&gt;&#xA;&lt;li&gt;The node type (instanceDetails.Api_Name) and its associated DBUs per hour (instanceDetails.Hourly_DBUs).&#xA;These should be accurate from the default load but Databricks may adjust their DBUs/Hour by node type. This is&#xA;especially true when a node goes from beta to GA.&lt;/li&gt;&#xA;&lt;li&gt;The DBU contract prices for the SKU under which your DBUs are charged such as:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Interactive&lt;/li&gt;&#xA;&lt;li&gt;Automated&lt;/li&gt;&#xA;&lt;li&gt;DatabricksSQL&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Databricks currently has 3 SKUs (classic/pro/serverless) but Overwatch is not able to accurately report&#xA;on DBSQL pricing at this time due to data not available in the customer-facing Databricks Product.&#xA;When this data becomes available, Overwatch will integrate it and enable DBSQL cost tracking. In the&#xA;meantime Overwatch will does it&amp;rsquo;s best to estimate DBSQL pricing so for this SKU just put your average&#xA;$DBU cost or a close estimate to your sku price here.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;JobsLight&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The DBU contract costs are captured from the&#xA;&lt;a href=&#34;https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/configuration//#databrickscontractprices&#34;&gt;Overwatch Configuration&lt;/a&gt; maintained&#xA;as a slow-changing-dimension in the &lt;a href=&#34;https://databrickslabs.github.io/overwatch/dataengineer/definitions//#dbucostdetails&#34;&gt;dbuCostDetails table&lt;/a&gt;.&#xA;The compute costs and dbu to node&#xA;associations are maintained as a slow-changing-dimension in the&#xA;&lt;a href=&#34;https://databrickslabs.github.io/overwatch/dataengineer/definitions//#instancedetails&#34;&gt;instanceDetails&lt;/a&gt; table.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Security Considerations</title>
      <link>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/securityconsiderations/</link>
      <pubDate>Tue, 13 Dec 2022 14:48:09 -0500</pubDate>
      <guid>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/securityconsiderations/</guid>
      <description>&lt;h2 id=&#34;api-access&#34;&gt;API Access&lt;/h2&gt;&#xA;&lt;p&gt;Overwatch utilizes several APIs to normalize the platform data. Overwatch leverages secret scopes and keys to acquire&#xA;a token that is authorized to access the platform. The account that owns the token (i.e. dapi token) must have&#xA;read access to the assets you wish to manage. If the token owner is a non-admin account the account must be granted&#xA;read level access to the assets to be monitored.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Configuration Validation</title>
      <link>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/validation/</link>
      <pubDate>Mon, 12 Dec 2022 11:36:53 -0500</pubDate>
      <guid>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/validation/</guid>
      <description>&lt;p&gt;Many validations are performed to minimize mistakes. The following section offers details on all validations&#xA;done. Not all validation steps are done on all runs. All validations should be performed before a first run on any&#xA;given workspace. For more information on executing a full validation, see &lt;a href=&#34;&#34;&gt;below&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;validation-rules&#34;&gt;Validation rules&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Name&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Validation Rule&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Impacted columns&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Api Url Validation&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;API URL should give some response with provided scope and key.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;api_url&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Primordial data validation&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Primordial Date must be in &lt;strong&gt;yyyy-MM-dd format&lt;/strong&gt; (i.e. 2022-01-30 == Jan 30, 2022) and must be less than current date.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;primordial_date&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Excluded scope validation&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Excluded scope must be null or in colon-delimited format and include only the following audit:sparkEvents:jobs:clusters:clusterEvents:notebooks:pools:accounts:dbsql&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;excluded_scopes&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Event Hub &lt;strong&gt;Shared Access Key&lt;/strong&gt; (Azure Only)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Audit Log data must be recognized as present and readable from the provided Event Hub Configuration fields.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;eh_name, eh_scope_key, secret_scope&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Event Hub &lt;strong&gt;AAD Auth&lt;/strong&gt; (Azure Only)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Audit Log data must be recognized as present and readable from the provided Event Hub Configuration fields.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;eh_name, eh_conn_string, aad_tenant_id, aad_client_id, aad_client_secret_key, aad_authority_endpoint&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Common consumer database name&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;All workspaces must have a common consumer database name.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;consumer_database_name&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Common ETL database name&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;All workspaces must have a common ETL database name.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;etl_database_name&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Storage prefix validation&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;All workspaces must share a single storage prefix and the Overwatch cluster must have appropriate access to read/write.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;storage_prefix&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Cloud provider validation&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Either Azure or AWS.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;cloud&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Max days validation&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Must Be a Number&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;max_days&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Secrete scope validation&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Secret scope must not be empty.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;secret_scope&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;PAT key validation&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;DBPAT must not be empty and must be able to authenticate to the workspace.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;secret_key_dbpat&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Audit log location validation &lt;strong&gt;(AWS/GCP ONLY)&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Audit logs must present immediately within the provided path and must be read accessible&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;auditlogprefix_source_path&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Mount point validation&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Workspaces with more than 50 mount points need to provide a csv file which will contain the mount point to source mapping. &lt;strong&gt;&lt;a href=&#34;https://databrickslabs.github.io/overwatch/dataengineer/advancedtopics//#exception---remote-workspaces-with-50-mounts&#34;&gt;click here for more details&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;mount_mapping_path&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;System Table Validation&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;System table should enabled and must have data for the workspace.&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;auditlogprefix_source_path&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;run-the-validation&#34;&gt;Run the validation&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; com.databricks.labs.overwatch.MultiWorkspaceDeployment&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; configCsvPath &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;dbfs:/FileStore/overwatch/workspaceConfig.csv&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// Path to the config.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// temp location which will be used as a temp storage. It will be automatically cleaned after each run.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; tempLocation &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/tmp/overwatch/templocation&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// number of workspaces to validate in parallel. Exceeding 20 may require larger drivers or additional cluster config considerations&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// If total workspaces &amp;lt;= 20 recommend setting parallelism == to workspace count &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; parallelism &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Run validation&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;MultiWorkspaceDeployment&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;configCsvPath&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; tempLocation&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;validate&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;parallelism&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;review-the-report&#34;&gt;Review The Report&lt;/h3&gt;&#xA;&lt;p&gt;The validation report will be generated in &amp;lt;etl_storage_prefix&amp;gt;/report/validationReport as delta table.&#xA;Run the below query to check the validation report. All records should say validated = true or action is necessary prior&#xA;to deployment.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Configuration Details By Version</title>
      <link>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/configdetailsbyversion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/configdetailsbyversion/</guid>
      <description>&lt;h2 id=&#34;overwatch-deployment-configuration-by-version&#34;&gt;Overwatch Deployment Configuration By Version&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#column-description-08xx&#34;&gt;0.8.x.x Configuration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#column-description-072x&#34;&gt;0.7.2.x Configuration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#column-description-071x&#34;&gt;0.7.1.x Configuration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;column-description-08xx&#34;&gt;Column description 0.8.x.x&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Column&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Type&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;IsRequired&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Description&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;workspace_name&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Name of the workspace.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;workspace_id&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Id of the workspace. &lt;strong&gt;MUST BE VALUE AFTER THE o=&lt;/strong&gt; in the URL bar. To ensure you get the right value, run the following on the target workspace. &lt;code&gt;Initializer.getOrgId&lt;/code&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;workspace_url&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;URL of the workspace. Should be in format of &lt;em&gt;https://*.com&lt;/em&gt; or &lt;em&gt;https://*.net&lt;/em&gt;. Don&amp;rsquo;t include anything after the .com or .net suffix&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;api_url&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;API URL for the Workspace (execute in scala &lt;code&gt;dbutils.notebook.getContext().apiUrl.get&lt;/code&gt; &lt;strong&gt;ON THE TARGET WORKSPACE NOT DEPLOYMENT WORKSPACE&lt;/strong&gt; to get the API URL for the workspace. NOTE: Workspace_URL and API_URL can be different for a workspace but may be the same even for multiple workspaces). You can also use the workspace_url here.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;cloud&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Cloud provider (Azure/AWS/GCP).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;primordial_date&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;The date from which Overwatch will capture the details. The &lt;strong&gt;format&lt;/strong&gt; should be &lt;strong&gt;yyyy-MM-dd&lt;/strong&gt; ex: 2022-05-20 == May 20 2022. **IMPORTANT NOTE: ** You should only set the primordial date in the initial run of Overwatch, and never change it again, as Overwatch will progress the dates using it&amp;rsquo;s own calculations and checkpoints.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;storage_prefix&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;CASE SENSITIVE - Lower Case&lt;/strong&gt; The location in which Overwatch will store the data. You can think of this as the Overwatch working directory. dbfs:/mnt/path/&amp;hellip; or abfss://container@myStorageAccount.dfs.core.windows.net/&amp;hellip; or s3://myBucket/&amp;hellip;   or gs://myBucket/&amp;hellip;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;etl_database_name&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;The name of the ETL data base for Overwatch (i.e. overwatch_etl or custom)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;consumer_database_name&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;The name of the Consumer database for Overwatch. (i.e. overwatch or custom)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;secret_scope&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Name of the secret scope. This must be created on the workspace which the Overwatch job will execute.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;secret_key_dbpat&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;This will contain the PAT token of the workspace. The key should be present in the secret_scope and should start with the letters &lt;em&gt;dapi&lt;/em&gt;.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;auditlogprefix_source_path&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;For all clouds use keyword &lt;strong&gt;system&lt;/strong&gt; to fetch data from System Tables (system.access.audit) See &lt;a href=&#34;https://databrickslabs.github.io/overwatch/deployoverwatch/systemtableintegration/systemtableconfiguration/&#34;&gt;System Table Configuration Details&lt;/a&gt; for details. If you are not using System Tables, you can enter the location of the auditlogs (&lt;strong&gt;AWS/GCP&lt;/strong&gt; Only). The contents under this directory must have the folders with the date partitions like date=2022-12-0 .&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;interactive_dbu_price&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Double&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Contract (or list) Price for interactive DBUs. The provided template has the list prices by default.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;automated_dbu_price&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Double&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Contract (or list) Price for automated DBUs. The provided template has the list prices by default.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;sql_compute_dbu_price&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Double&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Contract (or list) Price for DBSQL DBUs. This should be the closest average price across your DBSQL Skus (classic / Pro / Serverless) for now. See &lt;a href=&#34;https://databrickslabs.github.io/overwatch/deployoverwatch/configureoverwatch/customcosts/&#34;&gt;Custom Costs&lt;/a&gt; for more details. The provided template has the DBSQL Classic list prices by default.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;jobs_light_dbu_price&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Double&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Contract (or list) Price for interactive DBUs. The provided template has the list prices by default.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;max_days&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Integer&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;This is the max incrementals days that will be loaded. Usually only relevant for historical loading and rebuilds. Recommendation == 30&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;excluded_scopes&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;a href=&#34;https://databrickslabs.github.io/overwatch/dataengineer/modules//#scopes&#34;&gt;Scopes&lt;/a&gt; that should not be excluded from the pipelines. Since this is a CSV, it&amp;rsquo;s critical that these are &lt;strong&gt;colon delimited&lt;/strong&gt;. Leave blank if you&amp;rsquo;d like to load all overwatch scopes.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;active&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Boolean&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;True&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Whether or not the workspace should be validated / deployed.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;proxy_host&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Proxy url for the workspace.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;proxy_port&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Proxy port for the workspace&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;proxy_user_name&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Proxy user name for the workspace.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;proxy_password_scope&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Scope which contains the proxy password key.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;proxy_password_key&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Key which contains proxy password.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;success_batch_size&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Integer&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;API Tunable - Indicates the size of the buffer on filling of which the result will be written to a temp location. This is used to tune performance in certain circumstances. Leave default except for special circumstances. Default == 200&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;error_batch_size&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Integer&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;API Tunable - Indicates the size of the error writer buffer containing API call errors. This is used to tune performance in certain circumstances. Leave default except for special circumstances. Default == 500&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;enable_unsafe_SSL&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Boolean&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;API Tunable - Enables unsafe SSL. Default == False&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;thread_pool_size&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Integer&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;API Tunable - Max number of API calls Overwatch is allowed to make in parallel. Default == 4. Increase for faster bronze but if workspace is busy, risks API endpoint saturation. Overwatch will detect saturation and back-off when detected but for safety never go over 8 without testing.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;api_waiting_time&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Long&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;API Tunable - Overwatch makes async api calls in parallel, api_waiting_time signifies the max wait time in case of no response received from the api call. Default = 300000(5 minutes)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;mount_mapping_path&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Path to local CSV holding details of all mounts on remote workspaces (only necessary for remote workspaces with &amp;gt;50 mounts) &lt;strong&gt;&lt;a href=&#34;https://databrickslabs.github.io/overwatch/dataengineer/advancedtopics//#exception---remote-workspaces-with-50-mounts&#34;&gt;click here for more details&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;temp_dir_path&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;String&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;False&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Custom temporary working directory, directory gets cleaned up after each run.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h4 id=&#34;azure-event-hub-specific-configurations&#34;&gt;Azure Event Hub Specific Configurations&lt;/h4&gt;&#xA;&lt;p&gt;When configuring the Azure EH configurations users can use EITHER a &lt;strong&gt;shared access key&lt;/strong&gt; OR &lt;strong&gt;AAD SP as of 072x&lt;/strong&gt;&#xA;to authenticate to the EH. Below are the required configurations for each auth method. One of the options for Azure&#xA;deployments must be used as EH is required for Azure.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
