<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Engineering on Overwatch</title>
    <link>https://databrickslabs.github.io/overwatch/dataengineer/</link>
    <description>Recent content in Data Engineering on Overwatch</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 12 Dec 2022 11:41:13 -0500</lastBuildDate>
    <atom:link href="https://databrickslabs.github.io/overwatch/dataengineer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Modules / Scopes</title>
      <link>https://databrickslabs.github.io/overwatch/dataengineer/modules/</link>
      <pubDate>Mon, 12 Dec 2022 11:40:34 -0500</pubDate>
      <guid>https://databrickslabs.github.io/overwatch/dataengineer/modules/</guid>
      <description>&lt;h2 id=&#34;modules&#34;&gt;Modules&lt;/h2&gt;&#xA;&lt;p&gt;A module is a single workload that builds a target table. More details about all the modules are available in&#xA;&lt;a href=&#34;https://databrickslabs.github.io/overwatch/dataengineer/pipeline_management//#module-dependencies&#34;&gt;Pipeline Management&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;scopes&#34;&gt;Scopes&lt;/h2&gt;&#xA;&lt;p&gt;Scopes are the method by which Overwatch is segmented and a scope will contain all the related modules to build&#xA;the output from Bronze through to Gold. For example there&amp;rsquo;s one scope called &amp;ldquo;jobs&amp;rdquo; but it contains all the modules&#xA;for jobs and job runs from bronze through gold as well as the jobruncostpotentialfact gold fact table.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pipeline_Management</title>
      <link>https://databrickslabs.github.io/overwatch/dataengineer/pipeline_management/</link>
      <pubDate>Mon, 11 Jan 2021 12:21:46 -0500</pubDate>
      <guid>https://databrickslabs.github.io/overwatch/dataengineer/pipeline_management/</guid>
      <description>&lt;h2 id=&#34;overwatch-data-promotion-process&#34;&gt;Overwatch Data Promotion Process&lt;/h2&gt;&#xA;&lt;p&gt;Overwatch data is promoted from bronze - silver - gold - presentation to ensure data consistency and quality as the&#xA;data is enriched between the stages. The presentation layer is composed of views that reference the latest schema&#xA;version of the gold layer. This disconnects the consumption layer from the underlying data structure so that developers&#xA;can transparently add and alter columns without user disruption. All tables in each layer (except consumption) are&#xA;suffixed in the ETL database with &lt;em&gt;_layer&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Upgrades</title>
      <link>https://databrickslabs.github.io/overwatch/dataengineer/upgrade/</link>
      <pubDate>Thu, 20 May 2021 21:27:44 -0400</pubDate>
      <guid>https://databrickslabs.github.io/overwatch/dataengineer/upgrade/</guid>
      <description>&lt;p&gt;Sometimes upgrading from one version to the next requires a schema change. In these cases, the&#xA;&lt;a href=&#34;https://databrickslabs.github.io/overwatch/changelog/&#34;&gt;CHANGELOG&lt;/a&gt; will be explicit. Upgrades MUST be executed WITH the &lt;strong&gt;new library (jar)&lt;/strong&gt; and&#xA;&lt;strong&gt;before the pipeline is executed&lt;/strong&gt;.&#xA;Basic pseudocode can be found below as a reference. For actual version upgrade scripts please reference the upgrade&#xA;scripts linked to your target version in the &lt;a href=&#34;https://databrickslabs.github.io/overwatch/changelog/&#34;&gt;Changelog&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;div class=&#34;notices warning&#34; &gt;&lt;p&gt;When a schema upgrade is required between versions, &lt;strong&gt;this step cannot be skipped&lt;/strong&gt;. Overwatch will not allow you&#xA;to continue on a version that requires a newer schema.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Productionizing</title>
      <link>https://databrickslabs.github.io/overwatch/dataengineer/productionizing/</link>
      <pubDate>Wed, 20 Jul 2022 15:03:23 -0400</pubDate>
      <guid>https://databrickslabs.github.io/overwatch/dataengineer/productionizing/</guid>
      <description>&lt;h2 id=&#34;moving-to-production&#34;&gt;Moving To Production&lt;/h2&gt;&#xA;&lt;p&gt;When you&amp;rsquo;re ready to move to production, there are a few things to keep in mind and best practices to follow to&#xA;get the most out of Overwatch&lt;/p&gt;&#xA;&lt;h3 id=&#34;cluster-logging&#34;&gt;Cluster Logging&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Simplify and Unify your cluster logging directories&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Many users forget to enable cluster logging and without it Overwatch cannot provide usage telemetry by notebook,&#xA;job, user so it&amp;rsquo;s critical that all clusters have clusters logs enabled&lt;/li&gt;&#xA;&lt;li&gt;If users are allowed to create clusters/jobs without any governance, log files will be produced and stored all&#xA;over the place. These will be very challenging to clean up and can eat up a significant amount of storage over time.&lt;/li&gt;&#xA;&lt;li&gt;Utilize cluster policies to ensure the logging location is always set and done so consistently&lt;/li&gt;&#xA;&lt;li&gt;Set up a lifecycle policy (i.e. TTL) on your cluster logging directory in your cloud storage so the logs don&amp;rsquo;t&#xA;pile up indefinitely. Suggested time to live time is 30 days.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;backups&#34;&gt;Backups&lt;/h3&gt;&#xA;&lt;h4 id=&#34;this-will-be-deprecated-from-version-721please-refer-to-the-snapshot-section-for-the-new-way-to-do-backups&#34;&gt;(This will be Deprecated from version 7.2.1.Please refer to the Snapshot section for the new way to do backups)&lt;/h4&gt;&#xA;&lt;p&gt;&lt;strong&gt;Perform Bronze Backups&lt;/strong&gt;&#xA;I know we don&amp;rsquo;t hear a lot about backups in big data world but often times the cluster logs and / or&#xA;the audit logs are transient (especially Azure deployments as Event Hub only maintains 7 days). This means that if&#xA;something happened to the bronze data your Overwatch history could be lost forever. To guard against this it&amp;rsquo;s&#xA;strongly recommended that you periodically backup the Bronze data. As of 0.6.1.1 this has been made very easy through&#xA;the &lt;code&gt;snapshot&lt;/code&gt; helper function.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AdvancedTopics</title>
      <link>https://databrickslabs.github.io/overwatch/dataengineer/advancedtopics/</link>
      <pubDate>Mon, 12 Dec 2022 11:41:13 -0500</pubDate>
      <guid>https://databrickslabs.github.io/overwatch/dataengineer/advancedtopics/</guid>
      <description>&lt;h2 id=&#34;quick-reference&#34;&gt;Quick Reference&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#externalize-optimize--z-order-as-of-060&#34;&gt;Externalize Optimize &amp;amp; Z-Order&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#interacting-with-overwatch-and-its-state&#34;&gt;Interacting With Overwatch and its State&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#optimizing-overwatch&#34;&gt;Optimizing Overwatch&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#getting-a-strong-first-run&#34;&gt;Maximizing First Run Potential&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#historical-loading&#34;&gt;Historical Loads&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#cluster-logs-ingest-details&#34;&gt;Cluster Logs Ingest Details&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#joining-with-slow-changing-dimensions-scd&#34;&gt;Joining With Slow Changing Dimensions (SCD)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;optimizing-overwatch&#34;&gt;Optimizing Overwatch&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Expectation Check&lt;/strong&gt; Note that Overwatch analyzes nearly all aspects of the Workspace and manages its own pipeline&#xA;among many other tasks. This results in 1000s of spark job executions and as such, the Overwatch job will take some&#xA;time to run. For small/medium workspaces, 20-40 minutes should be expected for each run. Larger workspaces can take&#xA;longer, depending on the size of the cluster, the Overwatch configuration, and the workspace.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
